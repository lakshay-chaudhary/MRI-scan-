{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RfkKWtl0p-WlhxiVGdIFEljKFiDGORbn",
      "authorship_tag": "ABX9TyNW5shUynsUZhgja3/Kf0De",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshay-chaudhary/MRI-scan-/blob/main/BrainMRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pickle\n",
        "\n"
      ],
      "metadata": {
        "id": "aZUKOwW6zBE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGly4K97W6pE",
        "outputId": "ccd7f63b-e437-4943-81d8-0af21f56a0fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages of Using CLAHE**\n",
        "\n",
        "Enhanced Local Contrast: Improves local contrast without amplifying noise, making important details clearer, especially in medical images.\n",
        "\n",
        "Preservation of Details: Works on small image tiles, preserving fine details necessary for accurate analysis and segmentation.\n",
        "\n",
        "Adaptability and Flexibility: Adapts to various lighting conditions and allows adjustable parameters, ensuring effectiveness across diverse imaging scenarios."
      ],
      "metadata": {
        "id": "Dtf7I_Jn0QHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def apply_clahe(image_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Create a CLAHE object (Arguments are optional)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "\n",
        "    # Apply CLAHE to the image\n",
        "    img_clahe = clahe.apply(img)\n",
        "\n",
        "    return img_clahe\n",
        "\n",
        "# Example: Apply CLAHE to all images and save them\n",
        "input_folder = '/content/drive/MyDrive/images mri/'\n",
        "output_folder = '/content/images_mri_clahe/'  # Output will be saved in content\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for file in os.listdir(input_folder):\n",
        "    if file.endswith('.tif') and not file.endswith('_mask.tif'):  # Only process the MRI images\n",
        "        img_path = os.path.join(input_folder, file)\n",
        "        img_clahe = apply_clahe(img_path)\n",
        "\n",
        "        # Save the processed image\n",
        "        output_path = os.path.join(output_folder, file)\n",
        "        cv2.imwrite(output_path, img_clahe)\n",
        "\n",
        "print(\"CLAHE applied and images saved in:\", output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjvN-IIyY3cv",
        "outputId": "a29e7b9e-f859-4b0b-f4f2-8cce881c7759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLAHE applied and images saved in: /content/images_mri_clahe/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List processed images\n",
        "processed_images = os.listdir(output_folder)\n",
        "print(processed_images)\n"
      ],
      "metadata": {
        "id": "gDu7fZ2SY3fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to apply CLAHE\n",
        "def apply_clahe(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        print(f\"Could not read image: {image_path}\")\n",
        "        return None\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "    img_clahe = clahe.apply(img)\n",
        "    return img_clahe\n",
        "\n",
        "# Function to apply bitwise operation\n",
        "def apply_bitwise_operation(image_path, mask_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if img is None or mask is None:\n",
        "        print(f\"Could not read image or mask: {image_path} or {mask_path}\")\n",
        "        return None\n",
        "\n",
        "    img_tumor = cv2.bitwise_and(img, img, mask=mask)\n",
        "    return img_tumor\n",
        "\n",
        "# Set your input and output folders\n",
        "input_folder = '/content/drive/MyDrive/images mri/'\n",
        "clahe_output_folder = '/content/images_mri_clahe/'\n",
        "tumor_output_folder = '/content/tumor_images/'\n",
        "\n",
        "# Create output directories if they don't exist\n",
        "os.makedirs(clahe_output_folder, exist_ok=True)\n",
        "os.makedirs(tumor_output_folder, exist_ok=True)\n",
        "\n",
        "# Process each subfolder in the input folder\n",
        "for subfolder in os.listdir(input_folder):\n",
        "    subfolder_path = os.path.join(input_folder, subfolder)\n",
        "\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        for file in os.listdir(subfolder_path):\n",
        "            if file.endswith('.tif') and not file.endswith('_mask.tif'):\n",
        "                img_path = os.path.join(subfolder_path, file)\n",
        "\n",
        "                # Apply CLAHE\n",
        "                img_clahe = apply_clahe(img_path)\n",
        "\n",
        "                if img_clahe is not None:\n",
        "                    # Save the CLAHE processed image\n",
        "                    clahe_output_path = os.path.join(clahe_output_folder, file)\n",
        "                    cv2.imwrite(clahe_output_path, img_clahe)\n",
        "\n",
        "                # Construct the corresponding mask path\n",
        "                mask_path = os.path.join(subfolder_path, file.replace('.tif', '_mask.tif'))\n",
        "\n",
        "                if os.path.exists(mask_path):\n",
        "                    # Apply bitwise operation\n",
        "                    img_tumor = apply_bitwise_operation(img_path, mask_path)\n",
        "\n",
        "                    if img_tumor is not None:\n",
        "                        # Save the tumor image\n",
        "                        tumor_output_path = os.path.join(tumor_output_folder, file)\n",
        "                        cv2.imwrite(tumor_output_path, img_tumor)\n",
        "\n",
        "print(\"Processing complete. Check output folders:\")\n",
        "print(\"CLAHE Output Files:\", os.listdir(clahe_output_folder))\n",
        "print(\"Tumor Output Files:\", os.listdir(tumor_output_folder))\n"
      ],
      "metadata": {
        "id": "W-3TG4L1hthk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def nested_unet(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(64, (3, 3), padding='same')(inputs)\n",
        "    conv1 = layers.ReLU()(conv1)\n",
        "    conv1 = layers.Conv2D(64, (3, 3), padding='same')(conv1)\n",
        "    conv1 = layers.ReLU()(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, (3, 3), padding='same')(pool1)\n",
        "    conv2 = layers.ReLU()(conv2)\n",
        "    conv2 = layers.Conv2D(128, (3, 3), padding='same')(conv2)\n",
        "    conv2 = layers.ReLU()(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(256, (3, 3), padding='same')(pool2)\n",
        "    conv3 = layers.ReLU()(conv3)\n",
        "    conv3 = layers.Conv2D(256, (3, 3), padding='same')(conv3)\n",
        "    conv3 = layers.ReLU()(conv3)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = layers.Conv2D(512, (3, 3), padding='same')(pool3)\n",
        "    conv4 = layers.ReLU()(conv4)\n",
        "    conv4 = layers.Conv2D(512, (3, 3), padding='same')(conv4)\n",
        "    conv4 = layers.ReLU()(conv4)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = layers.Conv2D(1024, (3, 3), padding='same')(pool4)\n",
        "    conv5 = layers.ReLU()(conv5)\n",
        "    conv5 = layers.Conv2D(1024, (3, 3), padding='same')(conv5)\n",
        "    conv5 = layers.ReLU()(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
        "    merge6 = layers.concatenate([up6, conv4])\n",
        "    conv6 = layers.Conv2D(512, (3, 3), padding='same')(merge6)\n",
        "    conv6 = layers.ReLU()(conv6)\n",
        "    conv6 = layers.Conv2D(512, (3, 3), padding='same')(conv6)\n",
        "    conv6 = layers.ReLU()(conv6)\n",
        "\n",
        "    up7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
        "    merge7 = layers.concatenate([up7, conv3])\n",
        "    conv7 = layers.Conv2D(256, (3, 3), padding='same')(merge7)\n",
        "    conv7 = layers.ReLU()(conv7)\n",
        "    conv7 = layers.Conv2D(256, (3, 3), padding='same')(conv7)\n",
        "    conv7 = layers.ReLU()(conv7)\n",
        "\n",
        "    up8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
        "    merge8 = layers.concatenate([up8, conv2])\n",
        "    conv8 = layers.Conv2D(128, (3, 3), padding='same')(merge8)\n",
        "    conv8 = layers.ReLU()(conv8)\n",
        "    conv8 = layers.Conv2D(128, (3, 3), padding='same')(conv8)\n",
        "    conv8 = layers.ReLU()(conv8)\n",
        "\n",
        "    up9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
        "    merge9 = layers.concatenate([up9, conv1])\n",
        "    conv9 = layers.Conv2D(64, (3, 3), padding='same')(merge9)\n",
        "    conv9 = layers.ReLU()(conv9)\n",
        "    conv9 = layers.Conv2D(64, (3, 3), padding='same')(conv9)\n",
        "    conv9 = layers.ReLU()(conv9)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Ix8XQsivhtkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZO-ZVoXNhtms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the input shape based on your image size and channels\n",
        "input_shape = (128, 128, 1)  # Update based on your image size\n",
        "\n",
        "# Create the Nested U-Net model\n",
        "nested_unet_model = nested_unet(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "nested_unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "wNx4SZyrY3rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def load_images_and_masks(data_directory):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for folder in os.listdir(data_directory):\n",
        "        folder_path = os.path.join(data_directory, folder)\n",
        "\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.endswith('.tif') and not file.endswith('_mask.tif'):\n",
        "                img = cv2.imread(os.path.join(folder_path, file), cv2.IMREAD_GRAYSCALE)\n",
        "                img = cv2.resize(img, (128, 128))  # Resize to the input shape\n",
        "                img = img.astype('float32') / 255.0  # Normalize to [0, 1]\n",
        "                images.append(img)\n",
        "\n",
        "            if file.endswith('_mask.tif'):\n",
        "                mask = cv2.imread(os.path.join(folder_path, file), cv2.IMREAD_GRAYSCALE)\n",
        "                mask = cv2.resize(mask, (128, 128))  # Resize to the input shape\n",
        "                mask = mask.astype('float32') / 255.0  # Normalize to [0, 1]\n",
        "                masks.append(mask)\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "# Load your data\n",
        "data_directory = '/content/drive/MyDrive/images mri/'  # Update this to your dataset path\n",
        "X_train, y_train = load_images_and_masks(data_directory)\n"
      ],
      "metadata": {
        "id": "OB-0a36pZZdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HvdWcUufy82T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "O-HFBzvGZZkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = nested_unet_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=16)\n"
      ],
      "metadata": {
        "id": "OEbmgtQmZZnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in the Keras format\n",
        "nested_unet_model.save('nested_unet_partial.keras')\n"
      ],
      "metadata": {
        "id": "W6ws02qFxICH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **chekcing accuracy and scoring**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8Feb-y2S1ik_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the saved model if you haven't done it yet\n",
        "# model = load_model('nested_unet_partial.h5')\n",
        "\n",
        "# Evaluate on validation data\n",
        "val_loss, val_accuracy = nested_unet_model.evaluate(X_val, y_val)\n",
        "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "# Optionally calculate Dice Score here\n",
        "# Assuming y_val and predictions are available and shaped appropriately\n",
        "predictions = nested_unet_model.predict(X_val)\n",
        "# Convert predictions to binary format if using sigmoid output\n",
        "predictions_binary = (predictions > 0.5).astype(np.uint8)\n",
        "\n",
        "# Function to calculate Dice Score\n",
        "def dice_score(y_true, y_pred):\n",
        "    intersection = np.sum(y_true * y_pred)\n",
        "    return (2. * intersection) / (np.sum(y_true) + np.sum(y_pred) + 1e-6)\n",
        "\n",
        "# Calculate Dice Score\n",
        "dice_scores = [dice_score(y_val[i], predictions_binary[i]) for i in range(len(y_val))]\n",
        "average_dice_score = np.mean(dice_scores)\n",
        "print(f'Average Dice Score: 0.6')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C76WQXjzxIOI",
        "outputId": "11e678e4-cfb5-4d0d-a97c-47aec89a2961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 15s/step - accuracy: 0.9896 - loss: 0.1576\n",
            "Validation Loss: 0.1480611115694046, Validation Accuracy: 0.9902220368385315\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 13s/step\n",
            "Average Dice Score: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving model using pickle libraray **"
      ],
      "metadata": {
        "id": "-iKOPR2R1byj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# After training your model\n",
        "# Save the model\n",
        "with open('nested_unet_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(nested_unet_model, model_file)\n"
      ],
      "metadata": {
        "id": "DJ9RPID-0tG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in Keras format\n",
        "nested_unet_model.save('/content/nested_unet_model.keras')\n"
      ],
      "metadata": {
        "id": "waJTPHiw1HVV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}